{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "from google.cloud import aiplatform\n",
        "import bigframes.pandas as bpd\n",
        "import pandas as pd\n",
        "from vertexai.language_models._language_models import TextGenerationModel\n",
        "from bigframes.ml.cluster import KMeans\n",
        "from bigframes.ml.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "4riwiDAljBre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'qwiklabs-gcp-00-a6b6516bf3c9'\n",
        "dataset_name = \"ecommerce\"\n",
        "model_name = \"customer_segmentation_model\"\n",
        "table_name = \"customer_stats\"\n",
        "location = \"us-central1\"\n",
        "client = bigquery.Client(project=project_id)\n",
        "aiplatform.init(project=project_id, location=location)"
      ],
      "metadata": {
        "id": "2EdFJzBojE60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery\n",
        "CREATE OR REPLACE TABLE ecommerce.customer_stats AS\n",
        "SELECT\n",
        "  user_id,\n",
        "  DATE_DIFF(CURRENT_DATE(), CAST(MAX(order_created_date) AS DATE), day) AS days_since_last_order, ---RECENCY\n",
        "  COUNT(order_id) AS count_orders, --FREQUENCY\n",
        "  AVG(sale_price) AS average_spend --MONETARY\n",
        "  FROM (\n",
        "      SELECT\n",
        "        user_id,\n",
        "        order_id,\n",
        "        sale_price,\n",
        "        created_at AS order_created_date\n",
        "        FROM `bigquery-public-data.thelook_ecommerce.order_items`\n",
        "        WHERE\n",
        "        created_at\n",
        "            BETWEEN '2022-01-01' AND '2023-01-01'\n",
        "  )\n",
        "GROUP BY user_id;"
      ],
      "metadata": {
        "id": "WxRYDHOxjJqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the table ecommerce.customer_stats to a bigframes dataframe and show the top 10 records"
      ],
      "metadata": {
        "id": "cJb1YMV3mUqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Convert the table ecommerce.customer_stats to a bigframes dataframe and show the top 10 records\n",
        "\n",
        "import pandas as pd\n",
        "df_customer_stats = bpd.read_gbq(f'{project_id}.{dataset_name}.{table_name}')\n",
        "df_customer_stats.head(10)"
      ],
      "metadata": {
        "id": "wOdxjx4hmxvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: bqdf = client.read_gbq(f\"{project_id}.{dataset_name}.{table_name}\")\n",
        "# df.head(10)\n",
        "\n",
        "df = client.query(f\"SELECT * FROM `{project_id}.{dataset_name}.{table_name}`\").to_dataframe()\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "scCCqQFYnBFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bqdf = bpd.read_gbq(f\"{project_id}.{dataset_name}.{table_name}\")\n",
        "bqdf.head(10)"
      ],
      "metadata": {
        "id": "o_eDCzH2nFs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: #prompt: 1. Split df (using random state and test size 0.2) into test and training data for a K-means clustering algorithm store these as df_test and df_train. 2. Create a K-means cluster model using bigframes.ml.cluster KMeans with 5 clusters. 3. Save the model using the to_gbq method where the model name is project_id.dataset_name.model_name.\n",
        "# df_train, df_test = train_test_split(bq_df, test_siz\n",
        "\n",
        "df_train, df_test = train_test_split(bqdf, test_size=0.2, random_state=42)\n",
        "\n",
        "kmeans = KMeans(n_clusters=5)\n",
        "kmeans.fit(df_train)\n",
        "\n",
        "kmeans.to_gbq(f\"{project_id}.{dataset_name}.{model_name}\")"
      ],
      "metadata": {
        "id": "EvlR9VN3nHtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # prompt: 1. Call the K-means prediction model on the df dataframe, and store the results as predictions_df and show the first 10 records.\n",
        "# predictions_df = kmeans.predict(df_test)\n",
        "# predictions_df.head(10)\n",
        "\n",
        "predictions_df = kmeans.predict(df_test)\n",
        "predictions_df.head(10)"
      ],
      "metadata": {
        "id": "8RZVP9ANnL7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: #prompt: 1. Using predictions_df, and matplotlib, generate a scatterplot. 2. On the x-axis of the scatterplot, display days_since_last_order and on the y-axis, display average_spend from predictions_df. 3. Color by cluster. 4. The chart should be titled \"Attribute grouped by K-means cluster.\"\n",
        "# import matplotlib.pyplot as plt\n",
        "# # Create the scatter plot\n",
        "# plt.figure(figsize=(10, 6))  # Adjust figure s\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Create the scatter plot\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "plt.scatter(predictions_df['days_since_last_order'], predictions_df['average_spend'], c=predictions_df['CENTROID_ID'], cmap='viridis')\n",
        "plt.xlabel('Days Since Last Order')\n",
        "plt.ylabel('Average Spend')\n",
        "plt.title('Attribute grouped by K-means cluster')\n",
        "plt.colorbar(label='CENTROID_ID')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DmUF-tDKnr5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 1. Using predictions_df, and matplotlib, generate a scatterplot. 2. On the x-axis of the scatterplot, display days_since_last_order and on the y-axis, display average_spend from predictions_df. 3. Color by cluster. 4. The chart should be titled \"Attribute grouped by K-means cluster.\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Create the scatter plot\n",
        "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
        "plt.scatter(predictions_df['days_since_last_order'], predictions_df['average_spend'], c=predictions_df['CENTROID_ID'], cmap='viridis')\n",
        "plt.xlabel('Days Since Last Order')\n",
        "plt.ylabel('Average Spend')\n",
        "plt.title('Attribute grouped by K-means cluster')\n",
        "plt.colorbar(label='CENTROID_ID')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-eFp9yzWoaTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        " CONCAT('cluster ', CAST(centroid_id as STRING)) as centroid,\n",
        " average_spend,\n",
        " count_orders,\n",
        " days_since_last_order\n",
        "FROM (\n",
        " SELECT centroid_id, feature, ROUND(numerical_value, 2) as value\n",
        " FROM ML.CENTROIDS(MODEL `{0}.{1}`)\n",
        ")\n",
        "PIVOT (\n",
        " SUM(value)\n",
        " FOR feature IN ('average_spend',  'count_orders', 'days_since_last_order')\n",
        ")\n",
        "ORDER BY centroid_id\n",
        "\"\"\".format(dataset_name, model_name)\n",
        "\n",
        "df_centroid = client.query(query).to_dataframe()\n",
        "df_centroid.head()"
      ],
      "metadata": {
        "id": "Q75P5-srplah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_query = client.query(query).to_dataframe()\n",
        "df_query.to_string(header=False, index=False)\n",
        "\n",
        "cluster_info = []\n",
        "for i, row in df_query.iterrows():\n",
        " cluster_info.append(\"{0}, average spend ${2}, count of orders per person {1}, days since last order {3}\"\n",
        "  .format(row[\"centroid\"], row[\"count_orders\"], row[\"average_spend\"], row[\"days_since_last_order\"]) )\n",
        "\n",
        "cluster_info = (str.join(\"\\n\", cluster_info))\n",
        "print(cluster_info)"
      ],
      "metadata": {
        "id": "dv0TAsAeqOq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You're a creative brand strategist, given the following clusters, come up with \\\n",
        "creative brand persona, a catchy title, and next marketing action, \\\n",
        "explained step by step.\n",
        "\n",
        "Clusters:\n",
        "{cluster_info}\n",
        "\n",
        "For each Cluster:\n",
        "* Title:\n",
        "* Persona:\n",
        "* Next marketing step:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TMb2WwrmqQ7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: #prompt:  Use the Vertex AI language_models API to call the PaLM2 text-bison model and generate a marketing campaign using the variable prompt. Use the following model settings: max_output_tokens=1024, temperature=0.4\n",
        "# model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "# response = model.predict(prompt, max_output_tokens=1024, temperature=0.4)\n",
        "# print(response.text)\n",
        "\n",
        "model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
        "response = model.predict(prompt, max_output_tokens=1024, temperature=0.4)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "EpEbV8Y3qTNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JaYoCYv3rD4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}